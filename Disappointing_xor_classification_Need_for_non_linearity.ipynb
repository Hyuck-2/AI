{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.93988544 [[ 0.37000358]\n",
      " [-0.54427207]]\n",
      "100 0.7080561 [[-0.13458921]\n",
      " [-0.6474126 ]]\n",
      "200 0.6992675 [[-0.13474414]\n",
      " [-0.40945834]]\n",
      "300 0.6957489 [[-0.11075868]\n",
      " [-0.2576396 ]]\n",
      "400 0.694278 [[-0.08520995]\n",
      " [-0.16369843]]\n",
      "500 0.69364655 [[-0.06307261]\n",
      " [-0.10500659]]\n",
      "600 0.69337016 [[-0.04553376]\n",
      " [-0.06793638]]\n",
      "700 0.69324744 [[-0.03231361]\n",
      " [-0.04428156]]\n",
      "800 0.6931925 [[-0.02265383]\n",
      " [-0.02904729]]\n",
      "900 0.6931677 [[-0.01574077]\n",
      " [-0.01915627]]\n",
      "1000 0.69315654 [[-0.01086493]\n",
      " [-0.01268953]]\n",
      "1100 0.69315135 [[-0.00746188]\n",
      " [-0.0084366 ]]\n",
      "1200 0.6931491 [[-0.0051051 ]\n",
      " [-0.00562581]]\n",
      "1300 0.6931481 [[-0.00348241]\n",
      " [-0.00376058]]\n",
      "1400 0.69314754 [[-0.00237009]\n",
      " [-0.00251869]]\n",
      "1500 0.6931473 [[-0.00161019]\n",
      " [-0.00168957]]\n",
      "1600 0.69314724 [[-0.00109241]\n",
      " [-0.00113483]]\n",
      "1700 0.6931473 [[-0.00074034]\n",
      " [-0.00076299]]\n",
      "1800 0.6931472 [[-0.0005013 ]\n",
      " [-0.00051341]]\n",
      "1900 0.6931472 [[-0.00033922]\n",
      " [-0.00034569]]\n",
      "2000 0.6931472 [[-0.00022943]\n",
      " [-0.00023289]]\n",
      "2100 0.6931472 [[-0.0001551 ]\n",
      " [-0.00015695]]\n",
      "2200 0.6931472 [[-0.00010481]\n",
      " [-0.0001058 ]]\n",
      "2300 0.6931472 [[-7.080258e-05]\n",
      " [-7.133147e-05]]\n",
      "2400 0.6931472 [[-4.7822752e-05]\n",
      " [-4.8105787e-05]]\n",
      "2500 0.6931472 [[-3.2294247e-05]\n",
      " [-3.2441680e-05]]\n",
      "2600 0.6931472 [[-2.1806058e-05]\n",
      " [-2.1881973e-05]]\n",
      "2700 0.6931472 [[-1.47190685e-05]\n",
      " [-1.47607070e-05]]\n",
      "2800 0.6931472 [[-9.932068e-06]\n",
      " [-9.954333e-06]]\n",
      "2900 0.6931472 [[-6.696285e-06]\n",
      " [-6.708121e-06]]\n",
      "3000 0.6931472 [[-4.5236930e-06]\n",
      " [-4.5310585e-06]]\n",
      "3100 0.6931472 [[-3.0447522e-06]\n",
      " [-3.0476485e-06]]\n",
      "3200 0.6931472 [[-2.0605285e-06]\n",
      " [-2.0634247e-06]]\n",
      "3300 0.6931472 [[-1.3773090e-06]\n",
      " [-1.3772249e-06]]\n",
      "3400 0.6931472 [[-9.392126e-07]\n",
      " [-9.391285e-07]]\n",
      "3500 0.6931472 [[-6.337380e-07]\n",
      " [-6.336539e-07]]\n",
      "3600 0.6931472 [[-4.0724009e-07]\n",
      " [-4.0715597e-07]]\n",
      "3700 0.69314724 [[-2.7014912e-07]\n",
      " [-2.7006499e-07]]\n",
      "3800 0.6931472 [[-1.9489853e-07]\n",
      " [-1.9481440e-07]]\n",
      "3900 0.6931472 [[-1.3007823e-07]\n",
      " [-1.2999411e-07]]\n",
      "4000 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "4100 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "4200 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "4300 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "4400 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "4500 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "4600 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "4700 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "4800 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "4900 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "5000 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "5100 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "5200 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "5300 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "5400 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "5500 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "5600 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "5700 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "5800 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "5900 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "6000 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "6100 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "6200 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "6300 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "6400 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "6500 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "6600 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "6700 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "6800 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "6900 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "7000 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "7100 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "7200 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "7300 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "7400 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "7500 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "7600 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "7700 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "7800 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "7900 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "8000 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "8100 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "8200 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "8300 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "8400 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "8500 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "8600 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "8700 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "8800 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "8900 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "9000 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "9100 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "9200 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "9300 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "9400 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "9500 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "9600 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "9700 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "9800 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "9900 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "10000 0.6931472 [[-8.8354824e-08]\n",
      " [-8.8270696e-08]]\n",
      "\n",
      "Hypothesis: [[0.5]\n",
      " [0.5]\n",
      " [0.5]\n",
      " [0.5]]\n",
      "Correct: [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Accuracy: 0.500\n"
     ]
    }
   ],
   "source": [
    "x_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype = np.float32)\n",
    "y_data = np.array([[0], [1], [1], [0]], dtype = np.float32)\n",
    "\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "W = tf.Variable(tf.random.normal([2, 1]), name = 'weight')\n",
    "b = tf.Variable(tf.random.normal([1]), name = 'bias')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict = {X:x_data, Y:y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run(cost, feed_dict = {X:x_data, Y:y_data}), sess.run(W))\n",
    "        \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict = {X:x_data, Y:y_data})\n",
    "    print(f'\\nHypothesis: {h}\\nCorrect: {c}\\nAccuracy: {a:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Approach: Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7458046 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "100 0.48422438 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "200 0.2772231 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "300 0.16861741 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "400 0.10794185 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "500 0.07685366 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "600 0.057324193 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "700 0.04475522 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "800 0.036035076 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "900 0.029825957 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "1000 0.025237367 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "1100 0.021681057 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "1200 0.0189168 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "1300 0.016701402 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "1400 0.014892597 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "1500 0.01340474 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "1600 0.0121616125 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "1700 0.011102247 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "1800 0.010198057 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "1900 0.00940834 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "2000 0.008725261 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "2100 0.00812379 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "2200 0.0075933784 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "2300 0.007116812 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "2400 0.006695127 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "2500 0.0063117445 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "2600 0.005967789 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "2700 0.005658424 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "2800 0.0053745667 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "2900 0.005114469 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "3000 0.004879889 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "3100 0.004660734 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "3200 0.0044588298 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "3300 0.0042727636 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "3400 0.0040988307 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "3500 0.003937669 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "3600 0.0037893523 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "3700 0.0036497521 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "3800 0.0035188734 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "3900 0.0033968536 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "4000 0.0032819507 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "4100 0.0031734426 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "4200 0.0030720835 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "4300 0.0029758674 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "4400 0.0028846853 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "4500 0.0027987615 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "4600 0.0027177348 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "4700 0.0026405705 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "4800 0.0025671516 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "4900 0.002497641 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "5000 0.0024315706 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "5100 0.0023681675 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "5200 0.0023081591 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "5300 0.0022508306 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "5400 0.002195657 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "5500 0.0021431162 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "5600 0.002093104 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "5700 0.0020451394 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "5800 0.0019984331 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "5900 0.001954537 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "6000 0.0019117487 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "6100 0.0018710681 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "6200 0.0018318526 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "6300 0.0017937741 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "6400 0.0017574294 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "6500 0.0017223109 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "6600 0.0016885672 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "6700 0.0016559747 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "6800 0.0016244131 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "6900 0.0015940473 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "7000 0.0015646083 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "7100 0.0015360654 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "7200 0.0015088078 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "7300 0.0014823265 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "7400 0.0014563544 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "7500 0.0014314125 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "7600 0.0014074119 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "7700 0.0013839193 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "7800 0.0013612335 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "7900 0.0013392493 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "8000 0.0013177885 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "8100 0.0012971342 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "8200 0.0012768381 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "8300 0.0012573036 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "8400 0.0012382322 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "8500 0.0012196541 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "8600 0.0012015386 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "8700 0.0011840799 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "8800 0.0011670396 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "8900 0.0011503429 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "9000 0.0011341983 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "9100 0.001118457 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "9200 0.0011030145 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "9300 0.0010880048 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "9400 0.0010734281 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "9500 0.001058986 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "9600 0.0010451707 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "9700 0.0010315198 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "9800 0.0010183912 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "9900 0.0010053522 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "10000 0.0009928059 [[0.85094756]\n",
      " [1.618282  ]]\n",
      "\n",
      "Hypothesis: [[1.6374886e-03]\n",
      " [9.9918211e-01]\n",
      " [9.9910229e-01]\n",
      " [6.1589479e-04]]\n",
      "Correct: [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "Accuracy: 1.000\n"
     ]
    }
   ],
   "source": [
    "W1 = tf.Variable(tf.random.normal([2, 5]), name = 'weight1')\n",
    "b1 = tf.Variable(tf.random.normal([5]), name = 'bias1')\n",
    "layer1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random.normal([5, 1]), name = 'weight2')\n",
    "b2 = tf.Variable(tf.random.normal([1]), name = 'bias2')\n",
    "# tf.nn.relu shows a lower score???? why?\n",
    "# the last layer still uses sigmoid, since it has to return a number between 0 and 1\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "cost = -tf.reduce_mean(Y * tf.log(hypothesis) + (1 - Y) * tf.log(1 - hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate = 0.1).minimize(cost)\n",
    "\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype = tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype = tf.float32))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        sess.run(train, feed_dict = {X:x_data, Y:y_data})\n",
    "        if step % 100 == 0:\n",
    "            print(step, sess.run(cost, feed_dict = {X:x_data, Y:y_data}), sess.run(W))\n",
    "        \n",
    "    h, c, a = sess.run([hypothesis, predicted, accuracy], feed_dict = {X:x_data, Y:y_data})\n",
    "    print(f'\\nHypothesis: {h}\\nCorrect: {c}\\nAccuracy: {a:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wide NN can be more precise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random.normal([2, 10]), name = 'weight1')\n",
    "b1 = tf.Variable(tf.random.normal([10]), name = 'bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random.normal([10, 1]), name = 'weight2')\n",
    "b2 = tf.Variable(tf.random.normal([1]), name = 'bias2')\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1, W2) + b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# deep NN, also..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = tf.Variable(tf.random.normal([2, 10]), name = 'weight1')\n",
    "b1 = tf.Variable(tf.random.normal([10]), name = 'bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random.normal([10, 10]), name = 'weight2')\n",
    "b2 = tf.Variable(tf.random.normal([1]), name = 'bias2')\n",
    "layer2 = tf.sigmoid(tf.matmul(layer1, W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random.normal([10, 10]), name = 'weight2')\n",
    "b3 = tf.Variable(tf.random.normal([10]), name = 'bias2')\n",
    "layer2 = tf.sigmoid(tf.matmul(layer2, W3) + b3)\n",
    "\n",
    "....\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
