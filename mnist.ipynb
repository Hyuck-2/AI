{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.reshape([-1, 28*28])\n",
    "test_x = test_x.reshape([-1, 28*28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y_eye = np.eye(10)[train_y]\n",
    "test_y_eye = np.eye(10)[test_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x/255.\n",
    "test_x = test_x/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.02\n",
    "epoch = 500\n",
    "n_batch = 20\n",
    "batch_size = int(len(train_x)/n_batch)\n",
    "display_step = 20\n",
    "activation = tf.nn.relu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-3889852a000b>:10: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/pirl/anaconda3/envs/hyuck/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-8-3889852a000b>:11: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/pirl/anaconda3/envs/hyuck/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.device('device:GPU:0'):\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    X = tf.placeholder(dtype = tf.float32, shape = [None, 28*28])\n",
    "    Y = tf.placeholder(dtype = tf.float32, shape = [None, 10])\n",
    "    \n",
    "    keep_prob = tf.placeholder(dtype = tf.float32, shape = [])\n",
    "    \n",
    "    hidden1 = tf.layers.dense(X, 1024, activation=activation)\n",
    "    dropout1 = tf.nn.dropout(hidden1, keep_prob=keep_prob)\n",
    "    \n",
    "    hidden2 = tf.layers.dense(dropout1, 2048, activation=activation)\n",
    "    dropout2 = tf.nn.dropout(hidden2, keep_prob=keep_prob)\n",
    "    \n",
    "    logit = tf.layers.dense(dropout2, 10)\n",
    "    pred = tf.nn.softmax(logit)\n",
    "    \n",
    "    loss = tf.reduce_mean(tf.losses.softmax_cross_entropy(Y, logit))\n",
    "    #\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pred, 1), tf.argmax(Y, 1)),tf.float32))\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 20 loss currently at 0.07736432552337646\n",
      "Step 40 loss currently at 0.05624712258577347\n",
      "Step 60 loss currently at 0.044727690517902374\n",
      "Step 80 loss currently at 0.03283767029643059\n",
      "Step 100 loss currently at 0.043731629848480225\n",
      "Step 120 loss currently at 0.036375030875205994\n",
      "Step 140 loss currently at 0.04134982079267502\n",
      "Step 160 loss currently at 0.046827297657728195\n",
      "Step 180 loss currently at 0.04055628925561905\n",
      "Step 200 loss currently at 0.027607444673776627\n",
      "Step 220 loss currently at 0.03874732553958893\n",
      "Step 240 loss currently at 0.04285433515906334\n",
      "Step 260 loss currently at 0.04339078813791275\n",
      "Step 280 loss currently at 0.037821076810359955\n",
      "Step 300 loss currently at 0.04249660670757294\n",
      "Step 320 loss currently at 0.04288775101304054\n",
      "Step 340 loss currently at 0.042931366711854935\n",
      "Step 360 loss currently at 0.04199666529893875\n",
      "Step 380 loss currently at 0.032364651560783386\n",
      "Step 400 loss currently at 0.03776206821203232\n",
      "Step 420 loss currently at 0.028302719816565514\n",
      "Step 440 loss currently at 0.041282933205366135\n",
      "Step 460 loss currently at 0.027638692408800125\n",
      "Step 480 loss currently at 0.032946597784757614\n",
      "Step 500 loss currently at 0.045606840401887894\n",
      "Accuracy on the test set: 0.9677000045776367\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(epoch):\n",
    "        for i in range(n_batch):\n",
    "            batch_x = train_x[i*batch_size:(i+1)*batch_size]\n",
    "            batch_y = train_y_eye[i*batch_size:(i+1)*batch_size]\n",
    "            \n",
    "            _, l = sess.run([optimizer, loss], feed_dict = {X:batch_x, Y:batch_y, keep_prob:0.9})\n",
    "        losses.append(l)\n",
    "        if (step+1) % display_step == 0:\n",
    "            print(f'Step {step+1} loss currently at {l}')\n",
    "    \n",
    "    acc = sess.run(accuracy, feed_dict = {X:test_x, Y:test_y_eye, keep_prob:1.})\n",
    "    print(f'Accuracy on the test set: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
